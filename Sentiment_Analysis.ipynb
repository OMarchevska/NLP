{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17fad27e-5a39-44e2-a2ef-327e2bed98cf",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using Movie Reviews Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96a81da-0bda-4975-932c-6dcaebce31ba",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "69047b08-016d-4fbf-9f6a-a3bc03b03ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "from datetime import datetime\n",
    "import keras_nlp\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import tensorflow_models as tfm\n",
    "\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6f0afe9-757b-49b2-a8d0-b4b871021f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib settings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('font', size=14)\n",
    "plt.rc('axes', labelsize=14, titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da6f166-3225-44af-9069-bd5c30c0c78d",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51388b14-e465-4479-95a8-da5a69eb33f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train', 'imdb.vocab', 'test', 'README', 'imdbEr.txt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.keras.utils.get_file(\n",
    "    origin=\"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\",\n",
    "    extract=True, cache_dir='', cache_subdir=''\n",
    ")\n",
    "\n",
    "dataset_dir = os.path.join(os.path.dirname(dataset), \"aclImdb\")\n",
    "os.listdir(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2d5fff0-6886-4513-af17-cff7e8c3f5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['urls_pos.txt',\n",
       " 'urls_unsup.txt',\n",
       " 'neg',\n",
       " 'urls_neg.txt',\n",
       " 'labeledBow.feat',\n",
       " 'unsupBow.feat',\n",
       " 'pos',\n",
       " 'unsup']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set training and testing data paths\n",
    "train_dir = os.path.join(dataset_dir, \"train\")\n",
    "test_dir = os.path.join(dataset_dir, \"test\")\n",
    "\n",
    "os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7865f86d-f735-4abb-8011-768902d07f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['urls_pos.txt',\n",
       " 'urls_unsup.txt',\n",
       " 'neg',\n",
       " 'urls_neg.txt',\n",
       " 'labeledBow.feat',\n",
       " 'unsupBow.feat',\n",
       " 'pos']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove additional folders\n",
    "remove_dir = os.path.join(train_dir, 'unsup')\n",
    "shutil.rmtree(remove_dir)\n",
    "os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "136cbb92-f34d-4bb0-8009-efcce08f84b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "\n",
      "Class names: ['neg', 'pos']\n"
     ]
    }
   ],
   "source": [
    "# create datasets\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "train_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    train_dir, batch_size=batch_size, validation_split=0.2,\n",
    "    subset='training', labels=\"inferred\", seed=seed)\n",
    "\n",
    "val_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    train_dir, batch_size=batch_size, validation_split=0.2,\n",
    "    subset='validation', labels=\"inferred\", seed=seed)\n",
    "\n",
    "test_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    test_dir, batch_size=batch_size)\n",
    "\n",
    "class_labels = train_ds.class_names\n",
    "print(\"\\nClass names:\", class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4a2491e-34b5-4ec5-bb47-05504aa305a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Review: b'Belmondo is a tough cop. He goes after a big-time drug dealer (played by Henry Silva, normally a great villain - see \"Sharky\\'s Machine\"; but here he is clearly dubbed, and because of that he lacks his usual charisma). He goes to the scuzziest places of Paris and Marseilles, asks for some names, beats up some people, gets the names, goes to more scuzzy places, asks for more names, beats up more people, etc. The whole movie is punch after punch after punch. It seems that the people who made it had no other ambition than to create the French equivalent of \"Dirty Harry\". Belmondo, who was 50 here, does perform some good stunts at the beginning; apart from those, \"Le Marginal\" is a violent, episodic, trite, shallow and forgettable cop movie. (*1/2)'\n",
      "Label: neg: (0)\n",
      "\n",
      "Review: b'Wow. The only people reviewing this positively are the Carpenter apologists. I know a lot of those. The guys that\\'ll watch John Carpenter squat on celluloid and pinch out a movie and proclaim it a masterwork of horror. This \"movie\" is utter crap. It looks and sounds like a porno (good lord, the soundtrack is awful...), and has sub-par porn acting, which is shocking, because normally Ron Perlman is really a very good actor. I honestly have no idea what Carpenter was thinking when making this. Most likely \"Beans, beans, beans..\" until somebody fed him and rolled him up into a blanket for the day... They say nothing about the abortion debate whatsoever, when they could have had a very interesting central theme (how do religious zealot anti-abortionists feel when it\\'s the devil\\'s baby?) but instead they chose to have Ron Perlman and his terribly acted kids kill a bunch of people and have the horribly cast doctors try to calm the hysterically bad pregnant girl. Not a single person from this episode or what have you should come away unscathed. It\\'s just awful. Like, Plan 9 From Outerspace awful. Like, good god please would somebody turn it off before I soil myself awful. Try watching this and The Thing in the same day and your mind will implode.'\n",
      "Label: neg: (0)\n",
      "\n",
      "Review: b'Even though it has one of the standard \"Revenge Price Plots,\" this film is my favorite of Vincent Price\\'s work. Gallico has that quality that is missing in so many horror film characters- likeability. When you watch it, you feel for him, you feel his frustration, the injustices against him, and you cheer him on when he goes for vengeance, even though he frightens you a little with his original fury. As the film goes on, his character becomes tragic. He\\'s committed his murder, but now he must kill to cover that up. And again to cover that one up. And again... your stomach sinks with his soul as it goes down its spiral- like watching a beloved brother turn into a hood. Even if the revenge story is of old, the plot devices themselves are original- Gallico uses his tricks to kill in more and more inventive ways. A shame this one isn\\'t available for home veiwing.'\n",
      "Label: pos: (1)\n",
      "\n",
      "Review: b\"This is another one of those movies that could have been great. The basic premise is good - immortal cat people who kill to live, etc. - sort of a variation on the vampire concept.<br /><br />The thing that makes it all fall apart is the total recklessness of the main characters. Even sociopaths know that you need to keep a low profile if you want to survive - look how long it took to catch the Unibomber, and that was because a family member figured it out.<br /><br />By contrast, the kid (and to a lesser extent, the mom) behave as though they're untouchable. The kid kills without a thought for not leaving evidence or a trail or a living witness. How these people managed to stay alive and undiscovered for a month is unbelievable, let alone decades or centuries.<br /><br />It's really a shame - this could have been so much more if it had been written plausibly, i.e., giving the main characters the level of common sense they would have needed to get by for so long.<br /><br />Other than that, not a bad showing. I loved the bit at the end where every cat in town converges on the house - every time I put out food on the porch and see our cats suddenly rush in from wherever they were before, I think of that scene.\"\n",
      "Label: neg: (0)\n",
      "\n",
      "Review: b'\"Emma\" was a product of what might be called by the First Great Jane Austen Cycle of the mid-nineties, and it was recently shown on British television, doubtless because of the interest in the author created by the Second Great Jane Austen Cycle which started with \"Pride and Prejudice\" two years ago. We currently have in the cinemas the Austen biopic \"Becoming Jane\", and ITV have recently produced three TV movies based on Austen novels. These include \"Northanger Abbey\", the only one of the six major novels not to have been filmed previously, so the cycle should now be complete. No doubt, however, there will be more to come in the near future. (There is, after all, her juvenile \"Love and Freindship\" (sic), the short novella \"Lady Susan\", and someone, somewhere, has doubtless supplied endings to her two unfinished fragments \"The Watsons\" and \"Sanditon\". Then there are all those Austen sequels churned out by modern writers\\xc2\\x85\\xc2\\x85\\xc2\\x85).<br /><br />The main character is Emma Woodhouse, a young lady from an aristocratic family in Regency England. (Not, as some reviewers have assumed, Victorian England- Austen died before Queen Victoria was even born). Emma is, financially, considerably better off than most Austen heroines such as Elizabeth Bennett or Fanny Price, and has no need to find herself a wealthy husband. Instead, her main preoccupation seems to be finding husbands for her friends. She persuades her friend Harriet to turn down a proposal of marriage from a young farmer, Robert Martin, believing that Harriet should be setting her sights on the ambitious clergyman Mr Elton. This scheme goes disastrously wrong, however, as Elton has no interest in Harriet, but has fallen in love with Emma herself. The speed with which Emma rejects his proposal makes one wonder just why she was so keen to match her friend with a man she regards (with good reason) as an unsuitable marriage partner for herself. This being a Jane Austen plot, Emma turns out to be less of a committed spinster than she seems, and she too finds herself falling in love, leading to further complications.<br /><br />Emma always insists that she will not marry without affection, and when she does find a partner, the handsome Mr Knightley, we feel that this will indeed be an affectionate marriage. It does not, however, seem likely to be a very passionate one (unlike, say, that of Elizabeth Bennett and Mr Darcy). Knightley, who is sixteen years older than Emma (she is 21, he 37), and related to her by marriage, is more like a father-figure than a lover. Much more of a father-figure, in fact, than her actual father, a querulous and selfish old hypochondriac who seems more like her grandfather. When Emma is rude to her unbearably garrulous and tedious friend Miss Bates, it is Knightley who chides her for her lack of manners. (His surname is probably meant to indicate his gentlemanly nature- nineteenth-century gentlemen liked to think of themselves as the modern equivalent of mediaeval knights with their elaborate codes of chivalry). Both Gwyneth Paltrow and Jeremy Northam play their parts very well, but this is not really one of the great screen romances.<br /><br />Of the other characters, I liked Juliet Stephenson\\'s vulgar Mrs Elton and Toni Collette\\'s Harriet. I know that in the novel Harriet was a na\\xc3\\xafve young teenager, whereas here she is more like the character Collette played in \"Muriel\\'s Wedding\"- a gauche, slightly overweight twentysomething, fretting about her chances of finding a man. Nevertheless, I felt that this characterisation worked well in the context of the film and did not detract from Austen\\'s themes.<br /><br />\"Emma\" is one of Austen\\'s more light-hearted works, without the darker overtones of \"Mansfield Park\" or even \"Pride and Prejudice\", and this is reflected on screen. We see a world of beauty and grace, full of stately homes and elegant costumes and fine manners. Apart from the ruffianly gypsies, who make a very brief appearance, the only \"poor\" people we see are Mrs Bates and her daughter, and, as they live in the sort of picturesque rose-strewn thatched cottage which today would change hands for over \\xc2\\xa3500,000, we can be sure that their poverty is relative, not absolute. In Emma\\'s world, poverty is defined as not having your own stately home. This is, of course, not a comprehensive picture of early nineteenth-century life, but nobody has ever claimed Austen as the Regency equivalent of a kitchen-sink realist. Sophisticated romantic comedy, combined with a keen eye for analysing human character, was more in her line.<br /><br />I would not rate this film quite as highly as the 1994 \"Sense and Sensibility\" or the recent \"Pride and Prejudice\"- it tends to drag a bit in the middle, although it has a strong beginning and strong ending- but it is, in the main, a highly enjoyable Austen adaptation. 7/10'\n",
      "Label: pos: (1)\n"
     ]
    }
   ],
   "source": [
    "# data examples\n",
    "for review, label in train_ds.take(1):\n",
    "    for i in range(5):\n",
    "        print(f\"\\nReview: {review[i]}\")\n",
    "        print(f\"Label: {class_labels[label[i]]}: ({label[i]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36d3e618-bfa8-4e2c-9122-22a8ab3e7526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure datasets for performance\n",
    "train_ds = train_ds.cache().prefetch(-1)\n",
    "val_ds = val_ds.cache().prefetch(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a75254-c77c-47c4-a5a0-fefd1b611589",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dde6d7-2145-4898-94e8-b756c6f43335",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5ad5aa4-a41d-4e00-975e-94ca45156e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function to load the model\n",
    "def get_model(dropout=0.1):\n",
    "    model = keras_nlp.models.BertClassifier.from_preset(\n",
    "        \"bert_tiny_en_uncased_sst2\",\n",
    "        num_classes=2,\n",
    "        dropout=dropout,\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "779faf1a-fb54-402f-9669-401016a3c3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 1 variables whereas the saved optimizer has 2 variables. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"bert_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"bert_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ bert_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BertTokenizer</span>)                     │                                              <span style=\"color: #00af00; text-decoration-color: #00af00\">30,522</span> │\n",
       "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ bert_tokenizer (\u001b[38;5;33mBertTokenizer\u001b[0m)                     │                                              \u001b[38;5;34m30,522\u001b[0m │\n",
       "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"bert_classifier\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"bert_classifier\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                  </span>┃<span style=\"font-weight: bold\"> Output Shape                           </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
       "│ segment_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
       "│ bert_backbone (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BertBackbone</span>)                  │ {sequence_output: (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),   │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,385,920</span> │\n",
       "│                                               │ pooled_output: (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)}            │                 │\n",
       "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
       "│    └ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
       "│    └ token_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,906,816</span> │\n",
       "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
       "│    └ segment_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
       "│    └ position_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionEmbedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,536</span> │\n",
       "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
       "│    └ segment_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
       "│    └ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
       "│    └ embeddings_layer_norm                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)                          │                                        │                 │\n",
       "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
       "│    └ embeddings_dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
       "│    └ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
       "│    └ transformer_layer_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">198,272</span> │\n",
       "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
       "│    └ transformer_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">198,272</span> │\n",
       "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
       "│    └ tf.__operators__.getitem_2               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SlicingOpLambda</span>)                             │                                        │                 │\n",
       "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
       "│    └ pooled_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
       "│ logits (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
       "└───────────────────────────────────────────────┴────────────────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
       "│ segment_ids (\u001b[38;5;33mInputLayer\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
       "│ bert_backbone (\u001b[38;5;33mBertBackbone\u001b[0m)                  │ {sequence_output: (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),   │       \u001b[38;5;34m4,385,920\u001b[0m │\n",
       "│                                               │ pooled_output: (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)}            │                 │\n",
       "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
       "│    └ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
       "│    └ token_embedding (\u001b[38;5;33mReversibleEmbedding\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                      │       \u001b[38;5;34m3,906,816\u001b[0m │\n",
       "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
       "│    └ segment_ids (\u001b[38;5;33mInputLayer\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
       "│    └ position_embedding (\u001b[38;5;33mPositionEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                      │          \u001b[38;5;34m65,536\u001b[0m │\n",
       "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
       "│    └ segment_embedding (\u001b[38;5;33mEmbedding\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                      │             \u001b[38;5;34m256\u001b[0m │\n",
       "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
       "│    └ add_2 (\u001b[38;5;33mAdd\u001b[0m)                              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                      │               \u001b[38;5;34m0\u001b[0m │\n",
       "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
       "│    └ embeddings_layer_norm                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                      │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)                          │                                        │                 │\n",
       "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
       "│    └ embeddings_dropout (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                      │               \u001b[38;5;34m0\u001b[0m │\n",
       "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
       "│    └ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
       "│    └ transformer_layer_0 (\u001b[38;5;33mTransformerEncoder\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                      │         \u001b[38;5;34m198,272\u001b[0m │\n",
       "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
       "│    └ transformer_layer_1 (\u001b[38;5;33mTransformerEncoder\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                      │         \u001b[38;5;34m198,272\u001b[0m │\n",
       "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
       "│    └ tf.__operators__.getitem_2               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                            │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSlicingOpLambda\u001b[0m)                             │                                        │                 │\n",
       "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
       "│    └ pooled_dense (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                            │          \u001b[38;5;34m16,512\u001b[0m │\n",
       "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                            │               \u001b[38;5;34m0\u001b[0m │\n",
       "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
       "│ logits (\u001b[38;5;33mDense\u001b[0m)                                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                              │             \u001b[38;5;34m258\u001b[0m │\n",
       "└───────────────────────────────────────────────┴────────────────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,386,178</span> (16.73 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,386,178\u001b[0m (16.73 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,386,178</span> (16.73 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,386,178\u001b[0m (16.73 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c654a2a-aa9e-4121-ae20-ba0349e12da6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da60e49-6785-4ed8-b6ec-4259f619a7f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
